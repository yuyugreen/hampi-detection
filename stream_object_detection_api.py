from flask import Flask, render_template, Response
from flask_sslify import SSLify
import cv2
from datetime import datetime
import threading
import requests
import time
import ssl
import numpy as np
import os

from video_streamer import VideoStreamer

camera = VideoStreamer()

app = Flask(__name__)
context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)
context.load_cert_chain('/home/pi/cert.crt', '/home/pi/server_secret.key')

# ç‰©ä½“æ¤œå‡ºã«ã‚ˆã‚‹ä½ç½®ã®æƒ…å ±ã‚’ã€å…¥åŠ›ç”»åƒã®åº§æ¨™ã«
# ç‰©ä½“æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã¯(300, 300)
def scale_bounding_box_coordinate(image, target_bbox):
    # ç”»åƒã®ç¸¦ã‚µã‚¤ã‚º(shape[0])ã¨æ¨ªã‚µã‚¤ã‚º(shape[1])ã‚’å–å¾—
    image_height, image_width = image.shape[:2]

    # äºˆæ¸¬å€¤ã«å…ƒã®ç”»åƒã‚µã‚¤ã‚ºã‚’æ›ã‘ã¦ã€å››è§’ã§å›²ã‚€ãŸã‚ã®4ç‚¹ã®åº§æ¨™æƒ…å ±ã‚’å¾—ã‚‹
    coordinates = target_bbox[3:7] * (image_width, image_height, image_width, image_height)
    coordinates = coordinates.astype(np.int)[:4]  # ç”»åƒã«å››è§’ã‚„æ–‡å­—åˆ—ã‚’æ›¸ãè¾¼ã‚€ã«ã¯ã€åº§æ¨™æƒ…å ±ã¯intã§æ¸¡ã™å¿…è¦ãŒã‚ã‚‹ã€‚

    return coordinates

# ã‚¯ãƒ©ã‚¹åã¨å…±ã«BoundingBoxã‚’ç”»åƒã«æç”»
def draw_bounding_box_on_frame(image, target_bbox, class_name):
    coordinates = scale_bounding_box_coordinate(image, target_bbox)

    # floatã‹ã‚‰intã«å¤‰æ›ã—ã¦ã€å¤‰æ•°ã«å–ã‚Šå‡ºã™ã€‚
    # top_leftã¿ãŸã„ãªè¡¨è¨˜ã«å¤‰ãˆã‚‹ï¼Ÿ
    (start_X, start_Y, end_X, end_Y) = coordinates

    # BoundingBoxã‚’æç”»ã™ã‚‹
    # (ç”»åƒã€é–‹å§‹åº§æ¨™ã€çµ‚äº†åº§æ¨™ã€è‰²ã€ç·šã®å¤ªã•)ã‚’æŒ‡å®š
    # OpenCVã®é–¢æ•°ã‚’ä½¿ã†ãŸã‚ã€è‰²ã®æŒ‡å®šã¯BGRã®é †ã§è¡Œã†ã“ã¨ã«ç•™æ„
    cv2.rectangle(image, (start_X, start_Y), (end_X, end_Y), (255, 51, 51), thickness=2)

    # (ç”»åƒã€æ–‡å­—åˆ—ã€é–‹å§‹åº§æ¨™ã€ãƒ•ã‚©ãƒ³ãƒˆã€æ–‡å­—ã‚µã‚¤ã‚ºã€è‰²ã‚’æŒ‡å®š
    cv2.putText(image, class_name, (start_X, start_Y), cv2.FONT_HERSHEY_SIMPLEX, (.003*image.shape[1]), (255, 51, 51))

    return image

# LINE Notify APIã‚’ç”¨ã„ã¦ã€ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ç”»åƒã®ãƒ‘ã‚¹ã‚’å‚ç…§ã—æŠ•ç¨¿ã™ã‚‹
def post_image_to_line_notify(line_token, message, image_path, line_api_url):
    line_header = {'Authorization': 'Bearer ' + line_token}
    line_post_data = {'message': message}
    line_image_file = {'imageFile': open(image_path, 'rb')}
    res = requests.post(line_api_url, data=line_post_data, 
                        headers=line_header, files=line_image_file)
    print(res.text)

# detectionã«ã¯[?,idç•ªå·ã€äºˆæ¸¬ç¢ºç‡ã€Xã®é–‹å§‹ç‚¹ã€Yã®é–‹å§‹ç‚¹ã€Xã®çµ‚äº†ç‚¹ã€Yã®çµ‚äº†ç‚¹]ãŒå…¥ã£ã¦ã„ã‚‹ã€‚
def detect_target_object_box(image, model, model_input_size=(300, 300)):
    # OpenCVã¯BGRã§3ãƒãƒ£ãƒ³ãƒãƒ«ã®ã‚«ãƒ©ãƒ¼ç”»åƒã‚’æ‰±ã£ã¦ã„ã‚‹ãŸã‚ã€ã“ã“ã§swapRBã‚’Trueã«ã—ã¦å…¥åŠ›ç”»åƒã‚’RGBã®é †ã«å¤‰æ›
    model.setInput(cv2.dnn.blobFromImage(image, size=model_input_size, swapRB=True))

    # ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«å¯¾ã—ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰å‡¦ç†ã‚’å®Ÿæ–½ã€æ¨è«–çµæœã‚’å—ã‘å–ã‚‹
    model_outputs = model.forward()

    # model_outputsã¯[1:1:100:7]ã®ãƒªã‚¹ãƒˆã«ãªã£ã¦ã„ã‚‹ãŸã‚ã€å¾ŒåŠã®2ã¤ã‚’å–ã‚Šå‡ºã™
    detected_boxes = model_outputs[0, 0, :, :]  # 3æ¬¡å…ƒç›®ã«ã‚¯ãƒ©ã‚¹IDã€ï¼”æ¬¡å…ƒç›®ã«ãƒ¢ãƒ‡ãƒ«ãŒäºˆæ¸¬ã—ãŸç¢ºç‡

    return detected_boxes


@app.route('/')
def index():
    return render_template('index.html')

# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã—ã¤ã¤ã€ç‰©ä½“æ¤œå‡ºã—ãŸã‚‰LINEã¸é€šçŸ¥
def generate(camera):    
    PET_CLASS_ID = 1
    WAIT_SECOND = 600

    # ç‰©ä½“æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®ã‚¯ãƒ©ã‚¹idã¨å¯¾è±¡ç‰©ä½“åã®è¾æ›¸
    class_id_name_dict = {
        #0:'background',
        1:'hamster',
        2:'wheel',
        3:'toilet'
    }

    # LINE Notifyã¨ã®é€£æºã«é–¢ã™ã‚‹æƒ…å ±
    LINE_API_URL = 'https://notify-api.line.me/api/notify'
    LINE_API_TOKEN = os.environ['LINE_API_TOKEN']
    MESSAGE = 'ãƒãƒ ã‚¹ã‚¿ãƒ¼ãŒå‹•ãã¾ã—ãŸğŸ¹'

    CONFIDENCE = .5

    last_post_time = datetime(2000, 1, 1)  # ã“ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§é©å½“ãªæ—¥ä»˜ã§åˆæœŸåŒ–

    # Tensorflow Object Detection APIã§è¨“ç·´ã—ãŸç‰©ä½“æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
    # models/hogeãƒ•ã‚©ãƒ«ãƒ€ä»¥ä¸‹ã«ã€è©²å½“ãƒ¢ãƒ‡ãƒ«ã®pbåŠã³pbtxtãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ ¼ç´ã™ã‚‹
    model_name = '20200926_ssd_mobilenet_v2_momentum_no_transfer_hmn'
    model = cv2.dnn.readNetFromTensorflow('models/{}/frozen_inference_graph.pb'.format(model_name),
                                        'models/{}/frozen_inference_graph.pbtxt'.format(model_name))

    # æ¯ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¯¾ã—ã¦è¡Œã†å‡¦ç†
    while True:
        frame = camera.get_frame()  # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚«ãƒ¡ãƒ©ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰å–å¾—

        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ç‰©ä½“æ¤œå‡ºã—ãŸæ¨è«–çµæœã‚’å—ã‘å–ã‚‹ã€‚
        # detectionã«ã¯[?,idç•ªå·ã€äºˆæ¸¬ç¢ºç‡ã€Xã®é–‹å§‹ç‚¹ã€Yã®é–‹å§‹ç‚¹ã€Xã®çµ‚äº†ç‚¹ã€Yã®çµ‚äº†ç‚¹]ãŒå…¥ã£ã¦ã„ã‚‹ã€‚
        detected_boxes = detect_target_object_box(frame, model)

        # æ¤œå‡ºã—ãŸBoundingBoxã®ã†ã¡ã€äºˆæ¸¬ç¢ºç‡ãŒæœ€ã‚‚é«˜ã„æ ã ã‘æ®‹ã™ã€‚
        target_bboxes = {}
        for box in detected_boxes:
            for class_id in class_id_name_dict.keys():   
                if (box[1] == class_id) & (box[2] >= CONFIDENCE):
                    target_bboxes[class_id] = box

        # ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã«å¯¾è±¡ç‰©ä½“(class_id==1)ãŒæ¤œå‡ºã•ã‚ŒãŸã¨ãã€ç‰©ä½“ã®æ ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã«æç”»ã—ã€LINEã«ãã®ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã‚’æŠ•ç¨¿
        if PET_CLASS_ID in target_bboxes:
            # ã‚¯ãƒ©ã‚¹åã¨å…±ã«BoundingBoxã‚’æç”»
            frame = draw_bounding_box_on_frame(frame, target_bboxes[PET_CLASS_ID], class_id_name_dict[PET_CLASS_ID])
            
            # æœ€å¾Œã®æŠ•ç¨¿ã‹ã‚‰WAIT_SECONDä»¥ä¸ŠçµŒã£ã¦ã„ã‚‹å ´åˆã€LINEã¸ç‰©ä½“æ¤œå‡ºæ™‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ç”»åƒã‚’æŠ•ç¨¿
            now = datetime.now()
            if ((now - last_post_time).total_seconds() > WAIT_SECOND): 
                # ã¾ãšLINEã¸æŠ•ç¨¿ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜
                image_path = 'img/{}.jpg'.format(now.strftime('%Y%m%d%H%M%S'))
                cv2.imwrite(image_path, frame)

                # LINEã¸æŠ•ç¨¿
                post_image_to_line_notify(LINE_API_TOKEN, MESSAGE, image_path, LINE_API_URL)
                last_post_time = now

            # GCPã®IoT Coreã¸ãƒ­ã‚°ã‚’é€ä¿¡
            frame_height, frame_width = frame.shape[:2]
            for class_id in target_bboxes.keys():
                #class_name = class_id_name_dict[class_id]
                start_x = target_bboxes[class_id][3]
                start_y = target_bboxes[class_id][4]
                end_x = target_bboxes[class_id][5]
                end_y = target_bboxes[class_id][6]
                cmd = 'cd /home/pi/iotcore/; java -jar raspi-comfort-sensor-iotcore-1.0.jar ' 
                opt = '--start_x {} --start_y {} --end_x {} --end_y {} --frame_height {} --frame_width {}'  \
                .format(start_x, start_y, end_x, end_y, frame_height, frame_width)

                os.system(cmd + opt)

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã«å‘ã‘ãŸå‹å¤‰æ›
        frame_encode = cv2.imencode('.jpg',frame)[1]
        string_frame_data = frame_encode.tostring()

        yield (b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + string_frame_data + b'\r\n\r\n')


@app.route('/video_feed')
def video_feed():
    return Response(generate(camera),  # generateé–¢æ•°ã‹ã‚‰frameã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒ 
                    mimetype='multipart/x-mixed-replace; boundary=frame')

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, ssl_context=context, threaded=True, debug=False)
